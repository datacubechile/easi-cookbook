{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4edba860-5674-4738-8885-eb2ed0f25e6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Asynchronous S3 functions\n",
    "\n",
    "This notebook includes demonstrations and examples for using *async* `s3fs`.\n",
    "\n",
    "See [Async IO in Python: A Complete Walkthrough](https://realpython.com/async-io-python) for a comprehensive introduction to asynchronous capabilities in python.\n",
    "\n",
    "### Background on asynchronous S3 packages\n",
    "\n",
    "- [botocore]() and [boto3](). Two AWS packages that interface with underlying AWS APIs. Both are maintained.\n",
    "   - `botocore`. Closer implementation to the underlying AWS APIs\n",
    "   - `boto3`.\n",
    "- [aiobotocore](). Asynchronous interface to `botocore`. Sometimes critised for not being a pure async interface to the underlying AWS APIs.\n",
    "- [aioboto3](). Asynchronous interface to `boto3`. Only implements a few of the basic API functions for S3 and Dynamo\n",
    "- [s3fs](https://s3fs.readthedocs.io/en/latest/). Wrapper interface that lets S3 paths be used like file systems paths.\n",
    "   - Uses `aiobotocore` and has both *sync* and *async* function versions\n",
    "\n",
    "### Tips\n",
    "\n",
    "- `s3fs` *async* functions are named with a leading `_`, e.g. `_ls`, `_cp`, `_open`\n",
    "- `_list` and `_glob` functions return a list of items.\n",
    "- `_walk` and `_iterdir` are asynchronous generators (`async for`)\n",
    "\n",
    "### Index\n",
    "\n",
    "- [Imports and defaults](#Imports-and-defaults)\n",
    "- [Set up](#Set-up)\n",
    "- [Does a key exist](#Does-a-key-exist)\n",
    "- [List and filter keys](#List-and-filter-keys)\n",
    "- [Read a file](#Read-a-file)\n",
    "- [Download a set of keys](#Download-a-set-of-keys)\n",
    "- [Upload files](#Upload-files)\n",
    "- [Close session](#Close-session)\n",
    "- [Appendix: Filenames and paths](#Appendix:-Filenames-and-paths)\n",
    "- [Appendix: s3fs async vs sync functions](#Appendix:-s3fs-async-vs-sync-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041f5912-bfc8-4b94-bb14-adbc054fcd50",
   "metadata": {},
   "source": [
    "## Imports and defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd800436-87ab-49ff-825f-8e090a615829",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import s3fs\n",
    "import asyncio\n",
    "\n",
    "import aiobotocore\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import sys, re\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown\n",
    "import datetime as dt\n",
    "sys.path.insert(0, '/home/jovyan/easi-workflows')\n",
    "from tasks.utils.utils import elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcb8b6-7e1f-4c53-80c8-1e2142bd9591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s3://{bucket}/{prefix}/{dataset}/{datafile}\n",
    "bucket = 'easi-dc-data'\n",
    "prefix = 'products-index/copernicus_dem_30'\n",
    "dataset = 'Copernicus_DSM_COG_10_S10_00_E141_00_DEM'\n",
    "datafile = 'odc-metadata.yaml'\n",
    "notafile = 'doesnotexist.yaml'\n",
    "\n",
    "# Confirm that the S3 dataset exists\n",
    "x = f's3://{bucket}/{prefix}/{dataset}/{datafile}'\n",
    "! aws s3 ls {x}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b4ddbe-1472-4bd2-b9c8-5a4895c210a5",
   "metadata": {},
   "source": [
    "# Set up\n",
    "\n",
    "There are two options for authorization\n",
    "\n",
    "1. Create an [aiobotocore session](https://github.com/aio-libs/aiobotocore/blob/master/aiobotocore/session.py) > **Preferred if writing to S3**\n",
    "   - Provide an auth dict\n",
    "   - Read profiles from `~/.aws/config`\n",
    "   - Read `ENV` vars\n",
    "1. Let `s3fs` create an `aiobotocore session` > **Good for default or read-only**\n",
    "   - Parse selected keys, which doesn't include \"profile\"\n",
    "   - Create an `aiobotocore session` with basic auth keys\n",
    "   \n",
    "Each option in the next cells will work with this notebook, provided the default credentials are sufficient.\n",
    "\n",
    "> Recommend you select and uncomment the option you are using, and comment-out the other two, so that its clear which credentials you're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3166bae-1490-4730-9029-dcde5f273449",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# JupyterLab runs its own async loop, and python only has one so we use Jupyter's\n",
    "loop = asyncio.get_running_loop()\n",
    "\n",
    "# Default session\n",
    "s3 = s3fs.S3FileSystem(asynchronous=True, loop=loop)\n",
    "session = await s3.set_session()\n",
    "\n",
    "# ... Do work\n",
    "\n",
    "# To close later\n",
    "# await session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e2cf83-8f9e-4474-8fab-cfacb0c249eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple auth in a dict\n",
    "# !! Do not save AWS credentials in your notebook. Please return values to empty strings before saving !!\n",
    "# auth = {\n",
    "#     'aws_access_key_id': \"\",\n",
    "#     'aws_secret_access_key': \"\",\n",
    "#     'aws_session_token': \"\"\n",
    "# }\n",
    "# s3 = s3fs.S3FileSystem(asynchronous=True, loop=loop, client_kwargs=auth)\n",
    "# session = await s3.set_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef137a7-f92f-4acb-874f-0464543253f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom auth\n",
    "#\n",
    "# Add the following to your ~/.aws/config file. Safer than adding them to the notebook\n",
    "# [profile temporary_power_user]\n",
    "# aws_access_key_id=\n",
    "# aws_secret_access_key=\n",
    "# aws_session_token=\n",
    "\n",
    "# session = aiobotocore.session.AioSession(profile='temporary_power_user')\n",
    "# s3 = s3fs.S3FileSystem(asynchronous=True, loop=loop, session=session)\n",
    "# session = await s3.set_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845f6247-1c77-404c-b502-7e076dc99947",
   "metadata": {},
   "source": [
    "## Does a key exist\n",
    "\n",
    "Works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb716f-6595-436f-8200-beaa5758e570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = f'{bucket}/{prefix}/{dataset}/{datafile}'\n",
    "doesnotexist = f'{bucket}/{prefix}/{dataset}/{notafile}'\n",
    "\n",
    "display(Markdown('**Target exists**'))\n",
    "r = await s3._exists(target)\n",
    "print(r)\n",
    "\n",
    "display(Markdown('**Doesnotexist exists**'))\n",
    "r = await s3._exists(doesnotexist)\n",
    "print(r)\n",
    "\n",
    "display(Markdown('**Target is file**'))\n",
    "r = await s3._isfile(target)\n",
    "print(r)\n",
    "\n",
    "display(Markdown('**Target is directory**'))\n",
    "r = await s3._isdir(target)\n",
    "print(r)\n",
    "\n",
    "display(Markdown('**Target info**'))\n",
    "r = await s3._info(target)\n",
    "print(r)\n",
    "\n",
    "try:\n",
    "    r = await s3._info(doesnotexist)\n",
    "    display(Markdown('**Doesnotexist info**'))\n",
    "    print(r)\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9cbbd8-7ecd-417e-9a95-19d49db72b08",
   "metadata": {},
   "source": [
    "## List and filter keys\n",
    "\n",
    "- All seem to do a similar thing\n",
    "- `glob` and `find` work intuitively and similarly\n",
    "- Filter the resulting list if need be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4faf54-6e9a-41fa-8122-f629eb25ad2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = f'{bucket}/{prefix}/{dataset}'\n",
    "\n",
    "display(Markdown(f'**ls**'))\n",
    "r = await s3._ls(target)\n",
    "print(r)\n",
    "\n",
    "display(Markdown(f'**du \"directory\"**'))\n",
    "r = await s3._du(target)\n",
    "print(f'{r} bytes')\n",
    "\n",
    "display(Markdown(f'**du \"contents\"**'))\n",
    "fs = await s3._ls(target)\n",
    "for f in fs:\n",
    "    x = await s3._du(f)\n",
    "    print(f'{x} bytes: {f}')\n",
    "\n",
    "display(Markdown(f'**find**'))\n",
    "r = await s3._find(target)\n",
    "print(r)\n",
    "\n",
    "display(Markdown(f'**glob no \"/\"**'))\n",
    "r = await s3._glob(f'{target}')\n",
    "print(r)\n",
    "\n",
    "display(Markdown(f'**glob \"/\"**'))\n",
    "r = await s3._glob(f'{target}/')\n",
    "print(r)\n",
    "\n",
    "# We support \"**\", \"?\" and \"[..]\". We do not support ^ for pattern negation.\n",
    "display(Markdown(f'**glob \"/\\*yaml\"**'))\n",
    "r = await s3._glob(f'{target}/*yaml')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011e7e3-4c2d-4711-bebd-c2ca0d6ddf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# async generators\n",
    "\n",
    "display(Markdown(f'**iterdir \"/\"**'))\n",
    "count = 0\n",
    "async for item in s3._iterdir(bucket, prefix=f'{prefix}/'):\n",
    "    print(item)\n",
    "    count += 1\n",
    "    if count > 3 : break\n",
    "    \n",
    "\n",
    "# See https://docs.python.org/3/library/os.html#os.walk\n",
    "display(Markdown(f'**walk \"/\"**'))\n",
    "count = 0\n",
    "async for root, dirs, files in s3._walk(f'{bucket}/{prefix}/'):\n",
    "    print(f'Root: {root}')\n",
    "    print(f'Num dirs: {len(dirs)}')\n",
    "    print(f'Num files: {len(files)}')\n",
    "    count += 1\n",
    "    if count > 3 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbfc575-449a-4787-b820-4e13c682de60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# walk and filter with regex\n",
    "patt = re.compile('S1[0-2]_00_E14[1-3]')  # A subset of 'aust' for this example\n",
    "\n",
    "display(Markdown(f'**walk and filter with regex**'))\n",
    "found = []\n",
    "async for root, dirs, files in s3._walk(f'{bucket}/{prefix}/'):\n",
    "    if patt.search(root):\n",
    "        found.extend([f'{root}/{x}' for x in files if x.endswith('.yaml')])\n",
    "\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4681ab43-be31-4bcc-8431-d69501ea8fa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# glob and filter with regex\n",
    "aust = 'S1[0-2]_00_E14[0-5]'\n",
    "patt = re.compile('S1[0-2]_00_E14[1-3]')  # A subset of 'aust' for this example\n",
    "\n",
    "display(Markdown(f'**glob and filter with regex**'))\n",
    "r = await s3._glob(f'{bucket}/{prefix}/*{aust}*/*.yaml')\n",
    "   \n",
    "found = []\n",
    "for item in r:\n",
    "    if patt.search(item):\n",
    "        found.append(item)\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75210939-cc9f-4102-8821-fcd17a8bc04e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Large glob\n",
    "\n",
    "display(Markdown(f'**expand_path \"\\*tif\"**'))\n",
    "r = await s3._expand_path(f'{bucket}/{prefix}/*/*.tif')\n",
    "print(f'Number of items: {len(r)}')\n",
    "\n",
    "display(Markdown(f'**Large glob**'))\n",
    "r = await s3._glob(f'{bucket}/{prefix}/')\n",
    "print(f'Number of items: {len(r)}')\n",
    "\n",
    "display(Markdown(f'**Large glob \"\\*tif\"**'))\n",
    "r = await s3._glob(f'{bucket}/{prefix}/*/*.tif')\n",
    "print(f'Number of items: {len(r)}')\n",
    "\n",
    "display(Markdown(f'**Large glob \"\\*yaml\"**'))\n",
    "r = await s3._glob(f'{bucket}/{prefix}/*/*.yaml')\n",
    "print(f'Number of items: {len(r)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab048506-9d23-4d1d-9967-c99f97c362af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get_mapper - not async\n",
    "\n",
    "sync = s3fs.S3FileSystem(asynchronous=False)\n",
    "\n",
    "display(Markdown(f'**get_mapper**'))\n",
    "r = sync.get_mapper(f'{bucket}/{prefix}/')\n",
    "print(f'Number of items: {len(r)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bbe1ba-3961-49d2-97fe-bf4d42f5688f",
   "metadata": {},
   "source": [
    "## Read a file\n",
    "\n",
    "- *async* `_cat` works\n",
    "- Other open file functions appear to be *sync* only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c16cce-9d8f-4a3e-8daf-f10606b6bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = f'{bucket}/{prefix}/{dataset}/{datafile}'\n",
    "\n",
    "display(Markdown(f'**cat**'))\n",
    "r = await s3._cat(target)\n",
    "print(r.decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49edd60-5b1a-4e4c-83fd-c69a4b3075d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File open functions are not async\n",
    "\n",
    "sync = s3fs.S3FileSystem(asynchronous=False)\n",
    "\n",
    "display(Markdown(f'**head (sync)**'))\n",
    "r = sync.head(target, size=180)\n",
    "print(r.decode(\"utf-8\"))\n",
    "\n",
    "display(Markdown(f'**open (sync)**'))\n",
    "with sync.open(target) as f:\n",
    "    print(f.read().decode(\"utf-8\"))\n",
    "\n",
    "display(Markdown(f'**read_text (sync)**'))\n",
    "r = sync.read_text(target)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a75de37-e0d2-456a-97e6-2214ee32452f",
   "metadata": {},
   "source": [
    "## Download a set of keys\n",
    "\n",
    "- `get` and `put` work as expected files and dirs\n",
    "- *glob* paths also accepted\n",
    "- `copy` is untested (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9936401-5365-40f9-b71b-02ef5da18f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# File to targets\n",
    "\n",
    "# get, put and copy seem to return None(s) only\n",
    "\n",
    "target = f'{bucket}/{prefix}/{dataset}/{datafile}'\n",
    "workdir = '/home/jovyan/s3fs_test'\n",
    "\n",
    "display(Markdown(f'**get file > no-slash** (write to a file)'))\n",
    "_ = await s3._get(target, workdir)\n",
    "! ls -lh {workdir}\n",
    "! date\n",
    "! rm {workdir}\n",
    "\n",
    "display(Markdown(f'**get file > slash** (write to a dir)'))\n",
    "_ = await s3._get(target, f'{workdir}/')\n",
    "! ls -lh {workdir}/\n",
    "! date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f0006-ef7f-4ea3-af54-c00a0c69fe74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Directory to targets\n",
    "\n",
    "target = f'{bucket}/{prefix}/{dataset}'\n",
    "workdir = '/home/jovyan/s3fs_test'\n",
    "\n",
    "display(Markdown(f'**get dir > no-slash**'))\n",
    "_ = await s3._get(target, workdir, recursive=True)\n",
    "! ls -lh {workdir}/{dataset}\n",
    "! date\n",
    "\n",
    "display(Markdown(f'**get dir > slash**'))\n",
    "_ = await s3._get(target, f'{workdir}/', recursive=True)\n",
    "! ls -lh {workdir}/{dataset}\n",
    "! date\n",
    "\n",
    "display(Markdown(f'**copy**'))\n",
    "_ = await s3._copy(target, workdir)\n",
    "! ls -lh {workdir}/{dataset}\n",
    "! date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ede4a8-97ff-40b6-a5a4-a6f86677df88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Files + Dirs to targets\n",
    "# \"Can submit a list of paths, which may be glob-patterns and will be expanded.\"\n",
    "\n",
    "workdir = '/home/jovyan/s3fs_test'\n",
    "aust = 'S1[0-2]_00_E14[1-3]'\n",
    "target = f'{bucket}/{prefix}/*{aust}*/*.yaml'\n",
    "\n",
    "display(Markdown(f'**get a glob path to local**'))\n",
    "_ = await s3._get(target, f'{workdir}/aust/', recursive=True)\n",
    "! ls -lh {workdir}/aust/copernicus_dem_30/*\n",
    "! date\n",
    "\n",
    "# display(Markdown(f'**copy a glob path to local** - does not work as expected'))\n",
    "# _ = await s3._copy(target, f'{workdir}/aust/', recursive=True)\n",
    "# ! ls -lh {workdir}/aust/copernicus_dem_30/*\n",
    "# ! date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2256d99-e25f-4a60-924a-22c60d454488",
   "metadata": {},
   "source": [
    "## Upload files\n",
    "\n",
    "Pretty straightforward given what we now know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f97e3e6-ea69-45af-8b76-d80e358c6bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "userid = boto3.client('sts').get_caller_identity()['UserId']\n",
    "scratch = 'easihub-csiro-user-scratch'\n",
    "\n",
    "target = f'{scratch}/{userid}/s3fs_test'\n",
    "workdir = '/home/jovyan/s3fs_test'\n",
    "\n",
    "# Catch Access Denied\n",
    "try:\n",
    "    _ = await s3._put(f'{workdir}/aust/', f'{target}/', recursive=True)\n",
    "\n",
    "except (ClientError, PermissionError) as e:\n",
    "    print(e)\n",
    "    # Exit cell without traceback, https://stackoverflow.com/a/56953105\n",
    "    class StopExecution(Exception):\n",
    "        def _render_traceback_(self):\n",
    "            pass\n",
    "    raise StopExecution\n",
    "    \n",
    "\n",
    "display(Markdown(f'**glob** .../'))\n",
    "r = await s3._glob(f'{target}/')\n",
    "print(r)\n",
    "\n",
    "# Optional: More detail\n",
    "display(Markdown(f'**glob** .../copernicus_dem_30/'))\n",
    "r = await s3._glob(f'{target}/copernicus_dem_30/')\n",
    "print(r)\n",
    "\n",
    "display(Markdown(f'**glob** AWS equiv .../'))\n",
    "! aws s3 ls {target}/\n",
    "display(Markdown(f'**glob** AWS equiv .../copernicus_dem_30/'))\n",
    "! aws s3 ls {target}/copernicus_dem_30/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccaba95-99d6-4160-918c-1466c0115a96",
   "metadata": {},
   "source": [
    "## Close session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4a1088-3019-4a26-aee4-9dcdaee48ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Close session\n",
    "# await session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d36bb7-5f5c-4fbd-99fd-8a68d699ecdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Appendix: Filenames and paths\n",
    "\n",
    "Try a set of different formats for paths.\n",
    "\n",
    "#### Summary\n",
    "- *async* is faster, even in these simple tests\n",
    "- `s3://bucket/key`, `bucket/key`, and `Path(bucket/key)` all work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45532ecf-63cd-49db-9acf-c127c24334fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names_set = {\n",
    "    's3_prefix': {\n",
    "        'target': f's3://{bucket}/{prefix}/{dataset}/{datafile}',\n",
    "        'doesnotexist': f's3://{bucket}/{prefix}/{dataset}/{notafile}'\n",
    "    },\n",
    "    'bucket_noslash': {\n",
    "        'target': f'{bucket}/{prefix}/{dataset}/{datafile}',\n",
    "        'doesnotexist': f'{bucket}/{prefix}/{dataset}/{notafile}'\n",
    "    },\n",
    "    'bucket_slash': {\n",
    "        'target': f'/{bucket}/{prefix}/{dataset}/{datafile}',\n",
    "        'doesnotexist': f'/{bucket}/{prefix}/{dataset}/{notafile}'\n",
    "    },\n",
    "    'path_noslash': {\n",
    "        'target': Path(f'{bucket}/{prefix}/{dataset}/{datafile}'),\n",
    "        'doesnotexist': Path(f'{bucket}/{prefix}/{dataset}/{notafile}')\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf5b55-6dad-49c8-bbef-2fe8b17422b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = dt.datetime.now()\n",
    "\n",
    "# Synchronous\n",
    "sync = s3fs.S3FileSystem(asynchronous=False)\n",
    "\n",
    "for k,v in names_set.items():\n",
    "    display(Markdown(f'**{k}**'))\n",
    "    print( sync.ls(v['target']) )\n",
    "    print( sync.ls(v['doesnotexist']) )\n",
    "\n",
    "print(elapsed_time(dt.datetime.now()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9597af5-b8d3-4466-87ba-08f7ad62c567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = dt.datetime.now()\n",
    "\n",
    "# Asynchronous\n",
    "s3 = s3fs.S3FileSystem(asynchronous=True, loop=loop)\n",
    "session = await s3.set_session()\n",
    "\n",
    "for k,v in names_set.items():\n",
    "    display(Markdown(f'**{k}**'))\n",
    "    r = await asyncio.gather(*[\n",
    "        s3._ls(v['target']),\n",
    "        s3._ls(v['doesnotexist'])\n",
    "    ])\n",
    "    for x in r:\n",
    "        print(x)\n",
    "        \n",
    "print(elapsed_time(dt.datetime.now()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb35d9-7aa0-4a5e-b9c1-445dd3d67a6e",
   "metadata": {},
   "source": [
    "## Appendix: s3fs async vs sync functions\n",
    "\n",
    "Uncomment and test the various ways to correctly and incorrectly call the `s3fs` functions, using `ls` as an example.\n",
    "\n",
    "You may need to restart the kernal and return to here between each test.\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- Asynchronous functions use the following\n",
    "```python\n",
    "s3 = s3fs.S3FileSystem(asynchronous=True, loop=loop)\n",
    "session = await s3.set_session()\n",
    "r = await s3._ls(target)\n",
    "```\n",
    "- Synchronous functions use the following\n",
    "```python\n",
    "s3 = s3fs.S3FileSystem(asynchronous=False)\n",
    "r = s3.ls(target)\n",
    "```\n",
    "- \"Error: Loop is not running\" may indicate either\n",
    "   - an *async* `await` method is being used on a *sync* function, or\n",
    "   - a *sync* function is being used instead of an *async* one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21a3199-3b99-4191-bea6-d04de2eddf27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Synchronous\n",
    "sync = s3fs.S3FileSystem(asynchronous=False)\n",
    "\n",
    "target = names_set['path_noslash']['target']\n",
    "\n",
    "# sync func - Works\n",
    "display(Markdown('**sync func**'))\n",
    "r = sync.ls(target)\n",
    "\n",
    "# async func - Error: coroutine 'S3FileSystem._ls' was never awaited\n",
    "# display(Markdown('**async func**'))\n",
    "# r = sync._ls(target)\n",
    "\n",
    "# async func with await - Error: confusion in Jupyter's async loop\n",
    "# display(Markdown('**async func with await**'))\n",
    "# r = await sync._ls(target)\n",
    "\n",
    "# sync func with await - Error: object list can't be used in 'await' expression\n",
    "# display(Markdown('**sync func with await**'))\n",
    "# r = await sync.ls(target)\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3bcbf4-b45d-43cf-b04e-4f8bebdda4e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Asynchronous\n",
    "s3 = s3fs.S3FileSystem(asynchronous=True, loop=loop)\n",
    "session = await s3.set_session()\n",
    "\n",
    "target = names_set['path_noslash']['target']\n",
    "\n",
    "# sync func - Error: Loop is not running\n",
    "# display(Markdown('**sync func**'))\n",
    "# r = s3.ls(target)\n",
    "\n",
    "# async func - Object only, no calculations <coroutine object S3FileSystem._ls at ...>\n",
    "# display(Markdown('**async func**'))\n",
    "# r = s3._ls(target)\n",
    "\n",
    "# async func with await - Works\n",
    "display(Markdown('**async func with await**'))\n",
    "r = await s3._ls(target)\n",
    "\n",
    "# sync func with await - Error: Loop is not running\n",
    "# display(Markdown('**sync func with await**'))\n",
    "# r = await s3.ls(target)\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254f564-0812-4a7e-b201-fe08a0db0374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Close session\n",
    "# await session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32606e1e-d415-4909-86e3-0a437b0d8314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
